{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "explore_data.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/nathanbollig/distributed-mutation/blob/main/explore_data.ipynb",
      "authorship_tag": "ABX9TyP5FU7wtHh6d1JWNmowoZac",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathanbollig/distributed-mutation/blob/main/explore_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY1Lfh5kgtL7"
      },
      "source": [
        "# Explore Synthetic Data and Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKPEjUI1g0RJ"
      },
      "source": [
        "In Phase 1 and 2 of this project, synthetic viral sequence data is generated and a classification model is trained on 80% of this data. The result of running the `phases_1_and_2.py` script is a set results objects saved to disk into 6 pickle files. After performing Phase 1 and Phase 2, this notebook loads in these files and explores their contents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddXSXZAsxPkP"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO0lhqPxgnrO"
      },
      "source": [
        "## Phase 1 and 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZauKNjQ9gum7"
      },
      "source": [
        "This section follows the instructions in the project README to generate data and train a classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hne7sMQngizy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f45659f-580d-47b6-fb7b-833156711fd5"
      },
      "source": [
        "# Clone the git repository\n",
        "!git clone https://github.com/nathanbollig/distributed-mutation"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'distributed-mutation'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 46 (delta 20), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FFupudVUg86t",
        "outputId": "39ed63b9-b7c6-4135-9209-ad5c8d075b8c"
      },
      "source": [
        "# Apply requirements.txt\n",
        "%cd distributed-mutation\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/distributed-mutation\n",
            "Collecting hmmlearn==0.2.6\n",
            "  Downloading hmmlearn-0.2.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (374 kB)\n",
            "\u001b[K     |████████████████████████████████| 374 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting Keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 57.9 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.2\n",
            "  Downloading scikit_learn-0.22.2-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 15.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.5\n",
            "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from hmmlearn==0.2.6->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from hmmlearn==0.2.6->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->-r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->-r requirements.txt (line 2)) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->-r requirements.txt (line 2)) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.2->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->-r requirements.txt (line 4)) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->-r requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->-r requirements.txt (line 4)) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->-r requirements.txt (line 4)) (1.42.0)\n",
            "Collecting h5py\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 46.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->-r requirements.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->-r requirements.txt (line 4)) (1.13.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->-r requirements.txt (line 4)) (0.37.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 45.2 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.10\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->-r requirements.txt (line 4)) (1.1.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5->-r requirements.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->-r requirements.txt (line 4)) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->-r requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->-r requirements.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->-r requirements.txt (line 4)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->-r requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5->-r requirements.txt (line 4)) (3.10.0.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=dbe05188e60adbd7c205957d4e083af7ec9420f1c85abf0bb2bde563d40b2d60\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: numpy, h5py, tensorflow-estimator, tensorboard, scikit-learn, keras-applications, gast, tensorflow, Keras, hmmlearn\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "  Attempting uninstall: Keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Keras-2.2.4 gast-0.2.2 h5py-2.10.0 hmmlearn-0.2.6 keras-applications-1.0.8 numpy-1.18.5 scikit-learn-0.22.2 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "h5py",
                  "keras",
                  "numpy",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtauIY2Xi6Mr"
      },
      "source": [
        "The above conflicts are acceptable because these conflicts are with pre-installed packages in this environment that I don't believe are needed for executing my code. May now need to restart the runtime (and therefore change directory again)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhfwCQ9BiifG",
        "outputId": "2ce88972-169e-49fa-df27-da926d78935a"
      },
      "source": [
        "# Run script\n",
        "%cd distributed-mutation\n",
        "!bash phases_1_and_2.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/distributed-mutation\n",
            "Using TensorFlow backend.\n",
            "tcmalloc: large alloc 4800004096 bytes == 0x55994a792000 @  0x7f3ac9792001 0x7f3ac73367b5 0x7f3ac739ac00 0x7f3ac739ca9f 0x7f3ac7433078 0x5599263c7544 0x5599263c7240 0x55992643b627 0x5599264359ee 0x5599263c8bda 0x559926436915 0x5599263c8afa 0x559926436915 0x5599264359ee 0x5599263c8bda 0x559926437737 0x5599264359ee 0x5599264356f3 0x5599264ff4c2 0x5599264ff83d 0x5599264ff6e6 0x5599264d7163 0x5599264d6e0c 0x7f3ac857abf7 0x5599264d6cea\n",
            "tcmalloc: large alloc 3840000000 bytes == 0x559a68936000 @  0x7f3ac97901e7 0x7f3ac7336631 0x7f3ac739acc8 0x7f3ac739ade3 0x7f3ac7425f06 0x7f3ac7426368 0x5599264af409 0x559926436e7a 0x5599264359ee 0x5599263c8bda 0x559926437737 0x5599264359ee 0x5599263c8bda 0x559926436915 0x5599264b9cf8 0x5599264afcae 0x55992649fae5 0x5599263d6224 0x5599264070a4 0x5599263c7c52 0x55992643ac25 0x559926435ced 0x5599263c8bda 0x559926437737 0x5599264359ee 0x5599263c8bda 0x559926437737 0x5599264359ee 0x5599264356f3 0x5599264ff4c2 0x5599264ff83d\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2021-11-22 17:50:30.124111: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-11-22 17:50:30.131902: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2021-11-22 17:50:30.132191: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559928deca00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-22 17:50:30.132230: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "800000/800000 [==============================] - 17s 21us/step - loss: 0.0911 - acc: 0.9742\n",
            "Epoch 2/10\n",
            "800000/800000 [==============================] - 17s 21us/step - loss: 0.0559 - acc: 0.9793\n",
            "Epoch 3/10\n",
            "800000/800000 [==============================] - 17s 21us/step - loss: 0.0558 - acc: 0.9793\n",
            "Epoch 4/10\n",
            "800000/800000 [==============================] - 17s 21us/step - loss: 0.0558 - acc: 0.9793\n",
            "Epoch 5/10\n",
            "800000/800000 [==============================] - 17s 21us/step - loss: 0.0558 - acc: 0.9794\n",
            "Epoch 6/10\n",
            "800000/800000 [==============================] - 17s 21us/step - loss: 0.0558 - acc: 0.9794\n",
            "Epoch 7/10\n",
            "800000/800000 [==============================] - 17s 21us/step - loss: 0.0558 - acc: 0.9794\n",
            "Epoch 8/10\n",
            "800000/800000 [==============================] - 17s 21us/step - loss: 0.0558 - acc: 0.9794\n",
            "Epoch 9/10\n",
            "800000/800000 [==============================] - 17s 21us/step - loss: 0.0558 - acc: 0.9794\n",
            "Epoch 10/10\n",
            "800000/800000 [==============================] - 17s 21us/step - loss: 0.0558 - acc: 0.9793\n",
            "Train Accuracy: 97.98\n",
            "Validation Accuracy: 97.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3KxablrkQMw"
      },
      "source": [
        "## Explore Phase 1 and 2 Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg26JS-TkcI3"
      },
      "source": [
        "### Read in results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhXcQyLpkf1E",
        "outputId": "0f815748-dcf2-4f95-9f75-4388d2ba2c95"
      },
      "source": [
        "# Load model\n",
        "model = keras.models.load_model('model.tf')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_daNhizw-1S5"
      },
      "source": [
        "# Load pickled objects\n",
        "with open(\"aa_vocab.pkl\", 'rb') as pfile:\n",
        "    aa_vocab = pickle.load(pfile)\n",
        "with open(\"generator.pkl\", 'rb') as pfile:\n",
        "    gen = pickle.load(pfile)\n",
        "with open(\"result.pkl\", 'rb') as pfile:\n",
        "    result = pickle.load(pfile)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyr3KMlOkHTr"
      },
      "source": [
        "def get_test_data():\n",
        "    # Load test data\n",
        "    with open('data_test.txt') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    '''\n",
        "    Convert string representation of sequence in `sequences` to integer-encoded list\n",
        "    '''\n",
        "    def seq_str_to_list(s):\n",
        "        seq = s.split(',')\n",
        "        return list(map(int, seq))\n",
        "\n",
        "    # Read file into lists\n",
        "    X = []\n",
        "    y = []\n",
        "    for line in lines:\n",
        "        split_line = line.split('\\t')\n",
        "        seq = seq_str_to_list(split_line[0])\n",
        "        label = int(split_line[1])\n",
        "        X.append(seq)\n",
        "        y.append(label)\n",
        "\n",
        "    # Convert lists to arrays\n",
        "    X = np.array(X, dtype=int)\n",
        "    y = np.array(y, dtype=int)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "X, y = get_test_data()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33On35Stll3f",
        "outputId": "46dc9944-a953-4953-dd2e-ab2a90eb8855",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X[5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1, 15,  7,  1, 19,  8,  6,  7,  0,  7,  1,  1, 14, 11,  1, 19,  9,\n",
              "       11,  6,  5,  1,  9,  9,  9, 15, 18, 11,  2, 12, 15,  5,  3, 10, 10,\n",
              "       13, 19, 10,  8, 10, 10, 18,  0, 16,  9, 14, 19, 11, 10,  4, 19, 14,\n",
              "       16, 12, 13, 11, 12, 11,  2,  8,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4TeNcJdloW_",
        "outputId": "a94501af-f494-4ae8-ef7c-24da3ba0327f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y[5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifFVCGFClpRu"
      },
      "source": [
        "### Model and validation results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYlC3qNbluus"
      },
      "source": [
        "The Keras model object is stored in `model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVZIgrkcluEk",
        "outputId": "fe5d205f-8921-49b9-df4a-fd31b2194d1f"
      },
      "source": [
        "type(model)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.engine.sequential.Sequential"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sANnES3Rl6ki"
      },
      "source": [
        "During the training of this model, a dictionary was created of training set and validation set performance. We can display the values in this dictionary to see the accuracy of the stored model on its training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhYGeA76mBRb",
        "outputId": "aae45b83-77f3-4662-f8c8-14694be50469"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_train_accuracy': 0.979525, 'model_val_accuracy': 0.97968}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm3-FWr5mQwg"
      },
      "source": [
        "### Synthetic sequence data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbJubNbQmTxG"
      },
      "source": [
        "The data are sequences (variable names prefixed with `X`) and their labels (prefixed with `y`). Data is split into training, validation, and test sets. The training set was used to train the model and the validation set was used to measure the performance reported in the `result` dictionary. The test set has not yet been used for model training or evaluation.\n",
        "\n",
        "The data should be 80% training, 10% validation, and 10% test, with the total number of sequences as specified in the `phases_1_and_2.sh` script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFL6G855m_g8",
        "outputId": "b7d46fd4-b1f9-47a2-fdc4-e1a8e9aea7a5"
      },
      "source": [
        "len(X_train), len(X_val), len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800000, 100000, 100000)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrbJmM0YnJjn"
      },
      "source": [
        "As expected, there are the same number of labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13crO8qCnHj1",
        "outputId": "2adef25e-896b-4063-c4f2-1877b26845e8"
      },
      "source": [
        "len(y_train), len(y_val), len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800000, 100000, 100000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz3PLhOPnQk7"
      },
      "source": [
        "The sequence variables (`X_`*) are numpy arrays, where each sequence is represented by a 60 x 20 matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm53fyLVnSV3",
        "outputId": "90ad8307-0acc-4e12-819c-8f8cce65ed99"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800000, 60, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGrWHlrVnlOB"
      },
      "source": [
        "Each of the 60 positions in the sequence is represented by a one-hot vector of length 20. We assume that 20 is the size of the character alphabet. For example, a single sequence looks like the following matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-iN9FUNnmPA",
        "outputId": "a9ddce24-2db2-452c-f583-55b2668658de"
      },
      "source": [
        "X_train[42]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6qHBcU8omr5"
      },
      "source": [
        "The binary sequence label is an integer. The value 1 represents positive, and 0 represents negative. For example, the label for the above sequence is shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPnpjB-CoxOI",
        "outputId": "3cc6f9fc-48fd-4f4a-f5ca-6258c95f26b7"
      },
      "source": [
        "y_train[42]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O67nQig0oiBE"
      },
      "source": [
        "### Applying the model to a sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9nQXZ-ooz3H"
      },
      "source": [
        "We can apply the stored model to a sequence to get a prediction, using the TensorFlow model objects's API. For example, suppose we want to apply the model to sequences at index 42 and 43 in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMrF2REeo8NN",
        "outputId": "88d09f4c-886d-4c24-df18-15654126897e"
      },
      "source": [
        "model.predict(X_train[42:44])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00996366],\n",
              "       [0.01680388]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZumGgHzLpXjN"
      },
      "source": [
        "We see the prediction for each sequence as a number between 0 and 1. In this case, they are both close to 1, indicating higher confidence of positive. These predictions are correct in this context, as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kik3JggMplnq",
        "outputId": "96cc6163-0e9a-466c-d185-783e842605ce"
      },
      "source": [
        "y_train[42:44]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VNE61vkppoV"
      },
      "source": [
        "### Amino acid vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ7V2OijpvPI"
      },
      "source": [
        "The pickle file also included the amino acid vocabulary used for the encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3gHAGRHp3V1",
        "outputId": "3f8489cd-b725-4c94-8894-904fcdcf2d1d"
      },
      "source": [
        "print(aa_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drf89Wh7p8tb",
        "outputId": "953f342d-e811-47ee-f749-383504e35851"
      },
      "source": [
        "len(aa_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIOgt0aSp61b"
      },
      "source": [
        "This associates an index in the range 0-19 (as described above in relation to the one-hot representation of sequences) to a specific character that reflects an amino acid in the biological sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "974voIvGqOzR"
      },
      "source": [
        "### Markov model (HMMGenerator object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbOH7Md5qTx_"
      },
      "source": [
        "Finally, the pickle file includes the `HMMGenerator` object used to synthesize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4tN92tYqZMS",
        "outputId": "be82506e-2f90-44c1-fe2a-9d8f3213ecad"
      },
      "source": [
        "type(gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HMM_generator_motif.HMMGenerator"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcGydtPdqswd"
      },
      "source": [
        "This object has fields that determine the structure behind the synthesized data. For example, the sequence lengths, where the active site starts in a sequence, how long the active site is, the class proportion, the intensity of the positive class signal (as described in my report), emission probability distributions, transition mutation probabilities, and some others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AUhpXaAqcPr",
        "outputId": "0ba1ad44-4fc9-4c3d-d73e-d80977a2f9dd"
      },
      "source": [
        "print(gen.__dict__.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['seq_length', 'start', 'active_site_length', 'p', 'class_signal', 'aa_list', 'background_emission', 'state0_emission', 'state1_emissions', 'transmat', 'startprob', 'emissionprob', 'n_components', 'model'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A9DhrzDrTJj"
      },
      "source": [
        "The `HMMGenerator` class is a wrapper around a Multinomial Hidden Markov Model implemented in `hmmlearn`. The field `gen.model` contains the `hmmlearn` model used to synthesize data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzDScitLrY18",
        "outputId": "229216ca-6b69-4f36-95a4-690a93e9830f"
      },
      "source": [
        "type(gen.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "hmmlearn.hmm.MultinomialHMM"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f--TK3jGr2cU"
      },
      "source": [
        "## Using the generator to classify novel sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSS-zcc-rs15"
      },
      "source": [
        "The `HMMGenerator` class is capable of predicting the class 1 probability of a sequence under the existing HMM. Suppose we take a test item."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLniEQTCsNxf"
      },
      "source": [
        "x = X_test[42]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RQ5JSTZsQ6A",
        "outputId": "bef2eb32-01f4-4db1-ccc3-36dc2238d470"
      },
      "source": [
        "y = y_test[42]\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Bgp-n1sV-O"
      },
      "source": [
        "This is a negative instance. Make a mutation at position 35."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc4zI0idsTnp",
        "outputId": "e595bbb1-19ab-4c8d-a290-8242b40b2fc4"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08kDe3T4scrn",
        "outputId": "90b90fb3-425f-4323-cd38-1c715a3e3680"
      },
      "source": [
        "x[25]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpRgyOKushHR",
        "outputId": "ba370c09-015a-43eb-8014-9133e512c91e"
      },
      "source": [
        "old_char_idx = np.argmax(x[25])\n",
        "x[25][old_char_idx]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WgZCW7tsmGp"
      },
      "source": [
        "x[25][old_char_idx] = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXWnOW0Kso6i"
      },
      "source": [
        "x[25][11] = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FIPVBg1GsyUx",
        "outputId": "363fccad-76ff-4979-de57-c0330e11e359"
      },
      "source": [
        "aa_vocab[16]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'T'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "g1JtGQUYtRiu",
        "outputId": "50fdca30-ca35-4999-88d8-5ba7102447f1"
      },
      "source": [
        "aa_vocab[11]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'K'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUf7w8xKssUD"
      },
      "source": [
        "This corresponds to substituting the 16th character in the alphabet ('T') with the 11th character ('K'). Now we can predict the class label using the model (after reshaping into a batch of size 1), and predict the class label under the generator model (after converted to a sequence of indices rather than one-hot encoding)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6LT7BzqsrgZ",
        "outputId": "f384d677-c82c-4d1e-c9cb-2e26a50a8a79"
      },
      "source": [
        "# Model prediction on mutation\n",
        "model.predict(x.reshape(1,60,20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9999988]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOZ99415vFNy",
        "outputId": "82da49b2-4ce5-44c2-87e1-64bcc52a35f3"
      },
      "source": [
        "# Generator posterior prob of positive class\n",
        "gen.predict_proba(np.argmax(x, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999979333135554"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soXW1gZLvTOR"
      },
      "source": [
        "Make a few more mutations that I know should make it look like a positive sequence, then see that the generator indicates this looks more like a positive sequence, and the model correctly predicts this as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyLbtxmZvfha"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Set the following characters starting at index 26: 'RSFIED'\n",
        "chars = 'RSFIED'\n",
        "\n",
        "for i in range(26, 32):\n",
        "    # Get the new char index\n",
        "    char = chars[i-26]\n",
        "    new_char_idx = aa_vocab.index(char)\n",
        "\n",
        "    # Reset current char to 0\n",
        "    x[i][np.argmax(x[i])] = 0.0\n",
        "\n",
        "    # Make substitution for new char\n",
        "    x[i][new_char_idx] = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmqNxzslwjt4",
        "outputId": "f161f3bd-dd3d-45c0-d88b-6b64ab5124b1"
      },
      "source": [
        "# Generator posterior prob of positive class\n",
        "gen.predict_proba(np.argmax(x, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999978548146"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSwtJYR1wg-g",
        "outputId": "2471d342-771f-4ce4-af6a-83194964ce81"
      },
      "source": [
        "# Model prediction on mutation\n",
        "model.predict(x.reshape(1,60,20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6jl9msjGBFs"
      },
      "source": [
        "### Copy pickle files to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtLxgnQBG1O4"
      },
      "source": [
        "First need to mount Google Drive for this to work, and have a folder there called '744'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az_9ejuMGELU"
      },
      "source": [
        "# Copy files to Drive\n",
        "\n",
        "!cp *.* ../drive/MyDrive/744/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}